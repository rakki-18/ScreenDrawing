{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from scipy.signal import lfilter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = mp_hands.Hands(max_num_hands = 2, static_image_mode = False,min_detection_confidence = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing all the coordinates at different timesteps in a list\n",
    "list_x = []\n",
    "list_y = []\n",
    "list_z = []\n",
    "list_avg_x = []\n",
    "list_avg_y = []\n",
    "list_avg_z = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color and thickness of the lines\n",
    "color = (255,0,0)\n",
    "thickness = 2\n",
    "# threshold after which we should start drawing\n",
    "threshold = 5\n",
    "\n",
    "# threshold after which we should take base depth\n",
    "base_threshold = 4\n",
    "\n",
    "\n",
    "\n",
    "# moving average buffer\n",
    "k = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canvas on which we are drawing\n",
    "canvas = np.zeros([512,512,1],dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toggle = 1\n",
    "\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_depth = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_threshold = 10\n",
    "touch_threshold = -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "buffer_count = 0\n",
    "delay_count = 0\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    \n",
    "        \n",
    "    if not success:\n",
    "        print(\"video capture unsuccessful\")\n",
    "        break\n",
    "    \n",
    "    \n",
    "     \n",
    "    image = cv2.cvtColor(cv2.flip(image,1), cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "    \n",
    "    \n",
    "    \n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        \n",
    "        \n",
    "        \n",
    "        buffer_count = buffer_count+1\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        \n",
    "        # add the coordinates to the list\n",
    "        list_x.append(int(hand_landmarks.landmark[8].x*512))\n",
    "        list_y.append(int(hand_landmarks.landmark[8].y*512))\n",
    "        list_z.append(int(hand_landmarks.landmark[8].z*512))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if(buffer_count == k):\n",
    "            avg_x = sum(list_x[-k:])/k\n",
    "            avg_y = sum(list_y[-k:])/k\n",
    "            avg_z = sum(list_z[-k:])/k\n",
    "            \n",
    "            list_avg_x.append(int(avg_x))\n",
    "            list_avg_y.append(int(avg_y))\n",
    "            list_avg_z.append(int(avg_z))\n",
    "            buffer_count = 0\n",
    "            \n",
    "            #print('{0} {1} '.format(list_avg_z[-1] - base_depth, list_avg_z[-1]))\n",
    "            print(toggle)\n",
    "            \n",
    "            if(len(list_avg_z) == base_threshold):\n",
    "                base_depth = list_avg_z[-1]\n",
    "                \n",
    "            if(list_avg_z[-1] - base_depth > lift_threshold):\n",
    "                toggle = 0\n",
    "            if(list_avg_z[-1] - base_depth < touch_threshold):\n",
    "                toggle = 1\n",
    "            \n",
    "            if(len(list_avg_x) > threshold and toggle == 1):\n",
    "                # get the current coordinates as endpoint\n",
    "                end_point = (list_avg_x[-1], list_avg_y[-1])\n",
    "                # get the previous coordinates as the start point\n",
    "                start_point = (list_avg_x[-2], list_avg_y[-2])\n",
    "                # draw a line joining these points\n",
    "                cv2.line(canvas,start_point, end_point,color, thickness)\n",
    "                \n",
    "                \n",
    "                \n",
    "       \n",
    "        mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "    \n",
    "  \n",
    "    \n",
    "    # show the canvas and the webcam image   \n",
    "    cv2.imshow(\"Detected Hands\", image)\n",
    "    cv2.imshow(\"Result\", canvas)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # exit when the user presses 's's\n",
    "    if cv2.waitKey(5) & 0xFF == ord('s'):\n",
    "        break\n",
    "hands.close()\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_thumb)):\n",
    "    print(list_thumb[i] - list_z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
